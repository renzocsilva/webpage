---
title: 'Research data management: how to get to ''good enough'''
author: Renzo C. Silva
date: '2019-08-22'
slug: research-data-management-how-to-get-to-good-enough
categories: []
tags: []
description: ''
thumbnail: images/tn.png
---

## <span style="color:darkred">Why this post?</span>
  
Here I discuss a few key points, suggest external resources, and share personal experiences for those that have recognized the importance of changing their habits of research data management, but have not taken their first step in this journey.

This post is fully inspired by the nice (open access!) work of [Wilson et al. (2017)](https://doi.org/10.1371/journal.pcbi.1005510), in which a set of **good enough practices** in scientific computing is laid down. If you are an  research in the private sector or academia, and does not see any immediate benefit on adopting (any of) the suggestions shown therein... well, you better **wake up** *[and smell the coffee](https://www.youtube.com/watch?v=TGcHisWvmuo)*, because you may be stuck in old scientific practices that don't fit in our current society anymore. 
  

## <span style="color:darkred">Context</span>

Here I refer to again to [Wilson et al. (2017)](https://doi.org/10.1371/journal.pcbi.1005510), and recommend reading, in particular, the data management section *(~1100 words total, so have a go at it!)*. 

1. Save the raw data.  
2. Ensure that raw data are backed up in more than one location.  
3. Create the data you wish to see in the world.  
4. Create analysis-friendly data.  
5. Record all the steps used to process data.  
6. Anticipate the need to use multiple tables, and use a unique identifier for every
record.  
7. Submit data to a reputable DOI-issuing repository so that others can access and
cite it.  

It may seem like a big mountain to climb, but every journey starts with...*dramatic pause*... yeah, you know the cliche. 

## <span style="color:darkred">Is there help?</span>

If your organization has some IT resources you can access, **items 1 & 2** are just one phone call or e-mail, plus a few dollar and hours away from being done. Also ask for help with training, scheduled back-ups, and enforcing! *(more on enforcing later)*  Note: by raw data, we mean not altered in any way, as they come from their sources. Also, make sure the raw data is protected from editing (i.e., read-only). 

**Item 3** is a very important one, but often neglected. You do want to improve its readability for future reuse (by humans and bots). If not for the others and for the good of science, at least do it for selfish reasons as **YOU or YOUR TEAM** may be the ones wanting to reuse it. Think about the file format, variables names and file name. There is tons of resources out there providing a few guidelines (see the abovementioned paper and references therein). I have taken the [Research Data Management and Sharing](https://www.coursera.org/learn/data-management) course on Coursera and found it very useful. Note - I have been doing some searching on data from previous lives and now, 7+ years later, totally regret not having follow this advice back then. 

If you receive public funding for your research, you gotta pay close attention to their current or upcoming policies on research data management - it is such a hot topic right now. From the [national funding agencies in Canada](http://www.science.gc.ca/eic/site/063.nsf/eng/h_547652FB.html): *"[...] he agencies are committed to fostering a robust environment for data management in Canada and internationally, and to ensuring that Canadian researchers are well positioned to contribute to and capitalize on data-intensive science and scholarship. To support these commitments, the agencies expect the researchers they fund to manage their research data with the goal of realizing the greatest possible benefits for the research community and Canadian public."*

**Item 4**: make each column a variable, and each row an observation = analysis-friendly data. **Jump**. **Item 6**: anticipate the need to use multiple tables, and use a unique identifier for every record. I won't go deeper into these at this point in time. 

**Item 5**, **record all the steps used to process data**. You are about to archive some analysis-friendly data obtained from the raw data available in one of your back-ups. You want to make sure whatever you did, is reproducible! 
- If modifications were done via algorithms, show/store your code, good to go.  
- If not, things become harder. You should try at least use a version control solution so whenever required you can trace back modifications to files within a project. Here, your IT team can also help. Else check these answers on StackOverflow for [Windows](https://stackoverflow.com/questions/3376742/setup-an-svn-server), [Linux](https://stackoverflow.com/questions/60736/how-to-set-up-a-subversion-svn-server-on-gnu-linux-ubuntu), and [Mac OS](https://stackoverflow.com/questions/12530085/how-to-setup-svn-on-mac-os-x-10-8-2), and also [here](https://svnvsgit.com/) on why to pick SVN over GIT for our binary files. 

Park the data where people can easily access it, wither publicly or within your organization. DOI-issuing repositories are good as the data can be easily cited whenever necessary. 

## <span style="color:darkred">Personal experiences</span>

At work, we deal with many sources of raw scientific data. Data coming from instruments are immediatly backed-up in a few different locations, including off-site. Data from laboratory procedures are manually converted into raw data files and stored as well. Every team member has a smartpen capable of digitally recording all the laboratory notes. An SVN server provides version control capabilities, and users interaction are very straightfowards with TorsoiseSVN. Needless to say, the SVN server has also a system of back-ups. 

Regardless of the type of work done by the researcher within a project, "commits" are expected as often as significant advances are made. For those projects/users working with coding, private GIT repositories are also deployed in Github. For projects in which external access to data is required (e.g. off-campus stakeholders), a MySQL server hosted within the University data center feeds a R-Shiny dashboard where stakeholders can interact with data and reports. 


## Out of place

I don't know where it is, I have deleted it inadvertedly, my dog ate my data. 
Stakeholder enagement. 
De-personalizing a project
In academia, people come and go, so such setting is a must
Script to create directories


http://www.dcc.ac.uk/sites/default/files/documents/resource/DMP/DMP_Checklist_2013.pdf




**Cheers!**


