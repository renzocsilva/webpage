---
title: 'Research data management & "good enough" practices'
author: Renzo C. Silva
date: '2019-08-23'
slug: research-data-management-good-enough
categories: []
tags: []
description: ''
thumbnail: images/tn.png
---

## <span style="color:darkred">Why this post?</span>
  
This post is inspired by the nice (open access!) work of [Wilson et al. (2017)](https://doi.org/10.1371/journal.pcbi.1005510), in which a set of **good enough practices** in scientific computing is laid down. 

Here I build on a subset of topics presented there, discuss a few key points, suggest external resources, and share personal experiences for those that have recognized the importance of changing their habits on research data management but are yet to take their first step in this journey.

## <span style="color:darkred">Data management good enough practices</span>

Here is the checklist proposed by [Wilson et al. (2017)](https://doi.org/10.1371/journal.pcbi.1005510)  *(~1100 words total, so have a go at the comments they make on each topic!)*:

**1. **Save the raw data.  
**2. **Ensure that raw data are backed up in more than one location.  
**3. **Create the data you wish to see in the world.  
**4. **Create analysis-friendly data.  
**5. **Record all the steps used to process data.  
**6. **Anticipate the need to use multiple tables, and use a unique identifier for every record.  
**7. **Submit data to a reputable DOI-issuing repository so that others can access and cite it.  

It may seem like a big mountain to climb, but every journey starts with...*(dramatic pause)*... yeah, you know the cliche. `r emo::ji("wink")` 

<p align = 'center'><iframe src="https://giphy.com/embed/oQBGUspHX6JNe" width="240" height="180" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/scary-climb-aligator-oQBGUspHX6JNe"></a></p></p>

*If you are a researcher in the private sector or academia, and does not see any immediate benefit on adopting (any of) the suggestions shown therein... well, you better **wake up** *[(and smell the coffee)](https://www.youtube.com/watch?v=5mDrPKFsDVE)*, because you may be stuck in old scientific practices that don't fit in our current society anymore.*  

**I am encouraging you to go past the energy of activation**

## <span style="color:darkred">Is there help?</span>

**Items 1 & 2: Save the raw data. Ensure that raw data are backed up in more than one location.**  

If your organization has some IT resources that you can access, **items 1 & 2** are just one phone call or e-mail, plus a few dollars and hours away from being done. Don't be shy and also ask for help with the training of your team, and scheduled back-ups. **Note:** raw data means data that were not altered in any way, exactly as they come from their sources - ensure these files are protected from editing (i.e., read-only). Set your team free for experimenting without the worry of unintentionally damaging you dataset integrity.
  
  
**Item 3: Create the data you wish to see in the world.**  

You do want to improve your data readability for future reuse (by humans and bots). If not for the others, and for the good of science, selfish reasons may make you act because **YOU or YOUR TEAM** may be the ones wanting to reuse it. Think about the **file format, variable and file names**. Online resources providing guidelines on these topics are abundant. I found the [Research Data Management and Sharing](https://www.coursera.org/learn/data-management) course quite useful in this regard.

**Note - I have been doing some digging through my own datasets generated in previous lives, and now, 7+ years later, I humbly regret not having followed this advice back then.** 

If you receive public funding for your research, you better pay close attention to the current or upcoming policies on research data management set by the funding agencies - it is such a hot topic right now! **Something similar to [this](http://www.dcc.ac.uk/sites/default/files/documents/resource/DMP/DMP_Checklist_2013.pdf) is likely coming your way!** 

From the [federal funding agencies in Canada](http://www.science.gc.ca/eic/site/063.nsf/eng/h_547652FB.html): 


*"[...] the agencies are committed to fostering a robust environment for data management in Canada and internationally, and to ensuring that Canadian researchers are well positioned to contribute to and capitalize on data-intensive science and scholarship. To support these commitments, the agencies expect the researchers they fund to manage their research data with the goal of realizing the greatest possible benefits for the research community and Canadian public."*  
  
    
**Item 4: Create analysis-friendly data.**   

Let's skip it for now - out of scope.     
  
  
**Item 5: Record all the steps used to process data.** 

You are about to archive some analysis-friendly data obtained from the raw data available in one of your back-ups. **You want to make sure whatever you did to your data is reproducible!** *(For a comprehensive taste of the reproducibily crisis in science, see [this](https://www.nature.com/collections/prbfkwmwvz)))*  

- If changes to the raw data were done via algorithms, and you have a reproducible code for it, **then you are good to go!** `r emo::ji("clap")`  
- If not, well, things can get much trickier. Do you really know/recall all the options you clicked to make the spreadsheet you'll be using in further data analysis? A **version control software** solution allows you to track modifications to files within a project. That's not perfect for binary files but helps, and your IT team could assist you setting this up. **Feeling brave to give it a try yourself?** Check these StackOverflow Q&A for SVN solutions on [Windows](https://stackoverflow.com/questions/3376742/setup-an-svn-server), [Linux](https://stackoverflow.com/questions/60736/how-to-set-up-a-subversion-svn-server-on-gnu-linux-ubuntu), and [Mac OS](https://stackoverflow.com/questions/12530085/how-to-setup-svn-on-mac-os-x-10-8-2), and also [here](https://svnvsgit.com/) on why to pick SVN over GIT for your binary files. 
  
If you **combine a version control solution with effective back-ups**, get ready to enjoy some serious peace of mind! 
  
  
**Item 6: Anticipate the need to use multiple tables, and use a unique identifier for every record.**  

Let's skip it for now - out of scope.  
  
  
**Item 7: Submit data to a reputable DOI-issuing repository so that others can access and cite it.**  

Park the data where people can easily access it, wether publicly or within your organization. DOI-issuing repositories are helpful as the data can be easily cited whenever necessary. 


## <span style="color:darkred">Personal experience</span>

At work, we deal with many sources of raw scientific data. Data coming from instruments are immediately backed-up in a few different locations, including off-site. Data from laboratory procedures are manually converted into raw data files and stored as well. Every team member has a smartpen capable of recording (and backing-up) all the laboratory notes they take (**Items 1 and 2**). An SVN server provides version control capabilities, and users interact with it smoothly with [TorsoiseSVN](https://tortoisesvn.net/). Needless to say, the SVN server is also properly backed up (**Item 5**). Sample and work request databases provide the context/metadata info for each acquired raw data as required. 

Regardless of the type of work done by the researcher within a project, SVN "commits" are expected as often as significant advances are made. For projects in which external access to data is required (e.g. off-campus stakeholders), a MySQL server hosted within the University data center feeds an R-Shiny dashboard where stakeholders can interact with data and reports (**Items 3 and 7**). 

Once you have a system in place, the challenge becomes training the team and enforcing adherence to the practices you adopt. In academia setting, with people coming and going at an accelerated rate, enforcing is particularly difficult - but there is hope. I'll touch base on this again anytime soon. 

## <span style="color:darkred">Call for action</span>

- **Get help** and start setting your back-up and version control systems in place. Say goodbye to those days your data were at risk 24/7! *(no more 'the dog ate my file' or ['I need $30k to get my data back'](https://www.us-cert.gov/Ransomware) excuses)*
- Enhance your literacy in research data management. 
- Ensure progress. Set in your calendar to revisit this topic in 30 days and make sure you have taken solid steps towards better data management practices. 

**Cheers!**


