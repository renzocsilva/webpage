---
title: "USGS Geochemistry Database. Part I: Get that data"
author: Renzo C. Silva
date: '2019-09-04'
slug: usgs-geochemdb-part1
categories: []
tags: []
description: ''
thumbnail: images/tn.png
---

## Context 

For reasons beyond the scope of this blog (see [this publication](https://doi.org/10.1016/j.orggeochem.2019.103911), a follow up of my presentation at the [GRC Organic Geochemistry 2018](https://www.grc.org/organic-geochemistry-conference/2018/), I have done some serious data mining within the **United States Geological Survey (USGS) Geochemistry Database**. While chatting with peers at a conference, I realized many organic geochemists did not know about this resource, and those who knew about it, never went up [the hill](https://renzocsilva.ca/posts/hill-charts-in-r/) to check for information nuggets it may contain.

The goal of this series of posts about the USGS Geochemistry Database is to quick-start anyone remotely interested in exploring it. I'll be using **R**, but considering many still like doing their magic using a spreadsheet, I'll be spitting our any intermediate data table as **.csv** for such users.  


## Database information

All you need to know from the USGS Geochemistry Database can be found [here](https://certmapper.cr.usgs.gov/data/apps/geochem-db/). The database contains (geo)chemical analyses data of (allegedly) 200,000+ crude oil, natural gas, coal, water, and rock samples. It is used mostly to assess the oil and gas potential of sedimentary basins. 

The database was made public in a Microsoft Access format (.mdb) with ~ 400 Mb, and it is followed by a very useful excel file with relevant metadata and basic query instructions for those sticking with the Microsoft Access software. 


## Download --> Extract

The only tricky part of accessing the database using R is the use of drivers from the [RODBC](https://www.rdocumentation.org/packages/RODBC/versions/1.3-15) library that only work on the **R 32-bit version**.  

Running the code below, you will end up with two newly created folders: **raw_data**, containing the downloaded zip file plus the extracted database (.mdb) and metadata (.xls) files; and **extracted_data**, containing the whole 2 tables present in the database as .csv files - analysis.csv @ 227 Mb and samples.csv @ 28 Mb, approximately. **Note** that these file sizes make their processing not a challenge for the [modal](https://www.npr.org/2019/08/28/755191639/episode-936-the-modal-american) (as opossed to the average) desktop/laptop. On larger datasets, we would be using database queries as inputs to our data analysis down the road.

```{r initialization, echo = TRUE, eval = FALSE}
### Environment
library(RODBC)  ### Note: Must run on R 32-bits version

### User inputs
download_data <- TRUE # Change to FALSE after 1st execution
extract_to_csv <- TRUE # Change to FALSE after 1st execution
url <-
  "http://certmapper.cr.usgs.gov/data/geochem/tabular/EnergyGeochemistryPublicDB.zip"
filename <- "EnergyGeochemistryPublicDB.zip"

### Download and unzip
if (download_data == TRUE) {
  download.file(url, filename, mode = "wb")
  unzip(filename)
  
  # Organizing folder - tip: make this raw_data folder read-only!
  file.rename("Energy Geochemistry Public DB", "raw_data")
  file.copy(filename, paste0("./raw_data/", filename))
  file.remove(filename)
}

### Extract to csv
if (extract_to_csv == TRUE) {
  dir.create("extracted_data")
  channel <-
    odbcConnectAccess("./raw_data/Energy Geochemistry DB_9_2014.mdb")
  write.csv(sqlFetch(channel, "Analysis"), file = "./extracted_data/analysis.csv")
  write.csv(sqlFetch(channel, "Samples"), file = "./extracted_data/samples.csv")
  close(channel)
}
```


## What's next? 

It may not be a good idea to join the **analysis** and **sample** tables at this point. In Part II of this series, we'll get to know the data better and proceed with some clean up. 

**Cheers!**



